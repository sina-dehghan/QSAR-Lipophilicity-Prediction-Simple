"""
In this file, I am providing you the need visualization that can help us
to undestant this program better.

Author: Sina Dehghan + helps of our dear ChatGPT :D
"""
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from rdkit import Chem
from rdkit.Chem import Descriptors, AllChem, MACCSkeys, DataStructs
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb

# Set styl for better looking plots
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['font.size'] = 10

# Phase 1: Data Distribution Visualizations
# We use these for understaing our dataset before modeling

def plot_lipophilicity_distribution(df, save_path='plots/lipophilicity_distribution.png'):
    # df: DataFrame with 'Y' column which is for the lipophilicity

    print("\nðŸ“Š Creating lipophilicity distribution plot...")

    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # Plot 1: Histogram
    axes[0].hist(df['Y'], bins=50, color='steelblue', edgecolor='black', alpha=0.7)
    axes[0].set_xlabel('LogP (Lipophilicity)', fontsize=12, fontweight='bold')
    axes[0].set_ylabel('Number of Molecules', fontsize=12, fontweight='bold')
    axes[0].set_title('Distribution of Lipophilicity Values', fontsize=14, fontweight='bold')
    axes[0].axvline(df['Y'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df["Y"].mean():.2f}')
    axes[0].axvline(df['Y'].median(), color='green', linestyle='--', linewidth=2, label=f'Median: {df["Y"].median():.2f}')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)

    # Plot 2: Box Plot (for showing outliers and quartiles)
    axes[1].boxplot(df['Y'], vert=True, patch_artist=True,
                    boxprops=dict(facecolor='lightblue', color='steelblue'),
                    medianprops=dict(color='red', linewidth=2),
                    whiskerprops=dict(color='steelblue'),
                    capprops=dict(color='steelblue'))
    axes[1].set_ylabel('LogP (Lipophilicity)', fontsize=12, fontweight='bold')
    axes[1].set_title('Box Plot: Identifying Outliers', fontsize=14, fontweight='bold')
    axes[1].grid(True, alpha=0.3, axis='y')

    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"  âœ“ Saved to: {save_path}")
    plt.close()

def plot_molecular_property_correlations(df, save_path='plots/property_correlations.png'):
    # showing which molecular properties are related to each other
    # Better identifying redundant features
    # Red = Strong Positve Correlation, Blue = Strong Negative Correlation

    print("\nðŸ“Š Creating molecular property correlation heatmap...")

    # Calculate descriptors for a sample
    sample_size = min(500, len(df)) # Use 500 molecules or less
    sample_df = df.sample(n=sample_size, random_state=42)

    descriptor_names = [
        'MolWt', 'MolLogP', 'NumHDonors', 'NumHAcceptors',
        'TPSA', 'NumRotatableBonds', 'NumAromaticRings',
        'NumAliphaticRings', 'FractionCSP3', 'HeavyAtomCount'
    ]

    desc_data = []
    for smiles in sample_df['Drug']:
        mol = Chem.MolFromSmiles(smiles)
        if mol is not None:
            desc_values = [getattr(Descriptors, name)(mol) for name in descriptor_names]
            desc_data.append(desc_values)
    
    desc_df = pd.DataFrame(desc_data, columns=descriptor_names)

    # Calculate correlation matrix
    corr_matrix = desc_df.corr()

    # Create Heatmap
    plt.figure(figsize=(12, 10))
    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', 
                center=0, square=True, linewidths=1,
                cbar_kws={'label': 'Correlation Coefficient'})
    plt.title('Correlation Between Molecular Descriptors', fontsize=16, fontweight='bold', pad=20)
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"  âœ“ Saved to: {save_path}")
    plt.close()


# Phase 2: Model Performace Visualizations
# These will help us compare different models and descriptors
def plot_model_comparison_bars(results_df, save_path='plots/model_comparison.png'):
    # Creating bar charts comparing all model/descriptor combinations

    print("\nðŸ“Š Creating model comparison bar charts...")
    
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))

    # Create x-axis lables(descriptor + model)
    results_df['Label'] = results_df['Descriptor'] + '\n' + results_df['Model']
    x_pos = np.arange(len(results_df))

    # Color Palette for different descriptors
    colors = {'ECFP4': '#FF6B6B', 'MACCS': '#4ECDC4', 
              'RDKit': '#45B7D1', 'Combined': '#FFA07A'}
    bar_colors = [colors[desc] for desc in results_df['Descriptor']]
    
    # Plot 1:RÂ² Score (higher is better)
    axes[0].bar(x_pos, results_df['Test RÂ²'], color=bar_colors, edgecolor='black', linewidth=1.5)
    axes[0].set_ylabel('RÂ² Score', fontsize=12, fontweight='bold')
    axes[0].set_title('RÂ² Score Comparison\n(Higher is Better)', fontsize=14, fontweight='bold')
    axes[0].set_xticks(x_pos)
    axes[0].set_xticklabels(results_df['Label'], rotation=45, ha='right', fontsize=9)
    axes[0].axhline(y=0.8, color='green', linestyle='--', linewidth=2, alpha=0.5, label='Good (0.8)')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3, axis='y')

    # Plot 2: RMSE (lower is better)
    axes[1].bar(x_pos, results_df['Test RMSE'], color=bar_colors, edgecolor='black', linewidth=1.5)
    axes[1].set_ylabel('RMSE', fontsize=12, fontweight='bold')
    axes[1].set_title('RMSE Comparison\n(Lower is Better)', fontsize=14, fontweight='bold')
    axes[1].set_xticks(x_pos)
    axes[1].set_xticklabels(results_df['Label'], rotation=45, ha='right', fontsize=9)
    axes[1].grid(True, alpha=0.3, axis='y')

    # Plot 3: MAE (lower is better)
    axes[2].bar(x_pos, results_df['Test MAE'], color=bar_colors, edgecolor='black', linewidth=1.5)
    axes[2].set_ylabel('MAE', fontsize=12, fontweight='bold')
    axes[2].set_title('MAE Comparison\n(Lower is Better)', fontsize=14, fontweight='bold')
    axes[2].set_xticks(x_pos)
    axes[2].set_xticklabels(results_df['Label'], rotation=45, ha='right', fontsize=9)
    axes[2].grid(True, alpha=0.3, axis='y')

    # Add legend for descriptor colors
    from matplotlib.patches import Patch
    legend_elements = [Patch(facecolor=color, edgecolor='black', label=desc) 
                      for desc, color in colors.items()]
    fig.legend(handles=legend_elements, loc='upper center', ncol=4, 
              bbox_to_anchor=(0.5, 0.98), fontsize=11, title='Descriptor Type')
    
    plt.tight_layout()
    plt.subplots_adjust(top=0.88)
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"  âœ“ Saved to: {save_path}")
    plt.close()

def plot_metric_heatmap(results_df, save_path='plots/metric_heatmap.png'):
    # Showing all metrics across models or descriptors by a heatmap.
    print("\nðŸ“Š Creating metric heatmap...")

    fig, axes = plt.subplots(1, 3, figsize=(18, 6))

    metrics = ['Test RÂ²', 'Test RMSE', 'Test MAE']
    titles = ['RÂ² Score (Higher is Better)', 'RMSE (Lower is Better)', 'MAE (Lower is Better)']
    cmaps = ['Greens', 'Reds_r', 'Reds_r']  # _r means reversed colormap
    
    for idx, (metric, title, cmap) in enumerate(zip(metrics, titles, cmaps)):
        # Pivot data for heatmap
        pivot_data = results_df.pivot(index='Model', columns='Descriptor', values=metric)

        # Create heatmap
        sns.heatmap(pivot_data, annot=True, fmt='.4f', cmap=cmap, ax=axes[idx],
                    cbar_kws={'label': metric}, linewidths=2, linecolor='black')
        axes[idx].set_title(title, fontsize=12, fontweight='bold')
        axes[idx].set_xlabel('Descriptor Type', fontsize=11, fontweight='bold')

    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"  âœ“ Saved to: {save_path}")
    plt.close()


# Phase 3: Prediction Quality Visualization
def plot_predicted_vs_actual(df, descriptor_type='Combined', model_type='XGBoost', 
                             save_path='plots/predicted_vs_actual.png'):
    # Create scatter plot of Predicted vs Actual lipophilicity values.
    print(f"\nðŸ“Š Creating predicted vs actual plot ({descriptor_type} + {model_type})...")

    # Generate descriptors based on type
    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

    smiles_list = df['Drug'].tolist()
    y = df['Y'].values

    # Generate features based on descriptor type
    if descriptor_type == 'ECFP4':
        X = generate_ecfp4_fingerprints(smiles_list)
    elif descriptor_type == 'MACCS':
        X = generate_maccs_keys(smiles_list)
    elif descriptor_type == 'RDKit':
        X = generate_rdkit_descriptors(smiles_list)
    else:  # Combined
        X = generate_combined_descriptors(smiles_list)

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train model
    if model_type == 'Random Forest':
        model = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)
    else:  # XGBoost
        model = xgb.XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42)
    
    model.fit(X_train, y_train)

    
    # Make predictions
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)
    
    # Calculate metrics
    test_r2 = r2_score(y_test, y_test_pred)
    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
    test_mae = mean_absolute_error(y_test, y_test_pred)

    # Create plot
    fig, axes = plt.subplots(1, 2, figsize=(16, 6))
    
    # Plot 1: Training set
    axes[0].scatter(y_train, y_train_pred, alpha=0.5, s=50, color='steelblue', edgecolor='black', linewidth=0.5)
    axes[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 
                'r--', linewidth=3, label='Perfect Prediction')
    axes[0].set_xlabel('Actual LogP', fontsize=12, fontweight='bold')
    axes[0].set_ylabel('Predicted LogP', fontsize=12, fontweight='bold')
    axes[0].set_title(f'Training Set: {descriptor_type} + {model_type}', fontsize=14, fontweight='bold')
    axes[0].legend(fontsize=11)
    axes[0].grid(True, alpha=0.3)
    train_r2 = r2_score(y_train, y_train_pred)
    axes[0].text(0.05, 0.95, f'RÂ² = {train_r2:.4f}', transform=axes[0].transAxes,
                fontsize=12, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    # Plot 2: Test set
    axes[1].scatter(y_test, y_test_pred, alpha=0.6, s=50, color='coral', edgecolor='black', linewidth=0.5)
    axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
                'r--', linewidth=3, label='Perfect Prediction')
    axes[1].set_xlabel('Actual LogP', fontsize=12, fontweight='bold')
    axes[1].set_ylabel('Predicted LogP', fontsize=12, fontweight='bold')
    axes[1].set_title(f'Test Set: {descriptor_type} + {model_type}', fontsize=14, fontweight='bold')
    axes[1].legend(fontsize=11)
    axes[1].grid(True, alpha=0.3)
    axes[1].text(0.05, 0.95, f'RÂ² = {test_r2:.4f}\nRMSE = {test_rmse:.4f}\nMAE = {test_mae:.4f}', 
                transform=axes[1].transAxes, fontsize=11, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"  âœ“ Saved to: {save_path}")
    plt.close()

    return model, X_test, y_test, y_test_pred

def plot_residuals(y_test, y_test_pred, descriptor_type='Combined', model_type='XGBoost',
                   save_path='plots/residual_plot.png'):
    # Ploting residuals or prediction errors will help us for checking the patterns.

    print(f"\nðŸ“Š Creating residual plot ({descriptor_type} + {model_type})...")

    residuals = y_test - y_test_pred

    fig, axes = plt.subplots(1, 2, figsize=(16, 6))

    # Plot 1: Residuals vs Predicted
    axes[0].scatter(y_test_pred, residuals, alpha=0.6, s=50, color='purple', edgecolor='black', linewidth=0.5)
    axes[0].axhline(y=0, color='red', linestyle='--', linewidth=2)
    axes[0].set_xlabel('Predicted LogP', fontsize=12, fontweight='bold')
    axes[0].set_ylabel('Residuals (Actual - Predicted)', fontsize=12, fontweight='bold')
    axes[0].set_title(f'Residual Plot: {descriptor_type} + {model_type}', fontsize=14, fontweight='bold')
    axes[0].grid(True, alpha=0.3)
    axes[0].text(0.05, 0.95, 'Good: Random scatter around zero\nBad: Clear patterns', 
                transform=axes[0].transAxes, fontsize=10, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
    
    # Plot 2: Histogram of residuals
    axes[1].hist(residuals, bins=30, color='orange', edgecolor='black', alpha=0.7)
    axes[1].axvline(x=0, color='red', linestyle='--', linewidth=2)
    axes[1].set_xlabel('Residuals', fontsize=12, fontweight='bold')
    axes[1].set_ylabel('Frequency', fontsize=12, fontweight='bold')
    axes[1].set_title('Distribution of Residuals', fontsize=14, fontweight='bold')
    axes[1].grid(True, alpha=0.3, axis='y')
    axes[1].text(0.05, 0.95, f'Mean: {residuals.mean():.4f}\nStd: {residuals.std():.4f}', 
                transform=axes[1].transAxes, fontsize=11, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"  âœ“ Saved to: {save_path}")
    plt.close()

# Phase 4: Feature Importance Visualizations

def plot_feature_importance_rdkit(df, model_type='Random Forest', top_n=15,
                                 save_path='plots/feature_importance_rdkit.png'):
    
    print(f"\nðŸ“Š Creating feature importance plot (RDKit descriptors with {model_type})...")

    # Generate RDkit descriptors
    smiles_list =df['Drug'].tolist()
    y = df['Y'].values
    X = generate_rdkit_descriptors(smiles_list)             # Check it later.

    descriptor_names = [
        'MolWt', 'MolLogP', 'NumHDonors', 'NumHAcceptors',
        'TPSA', 'NumRotatableBonds', 'NumAromaticRings',
        'NumAliphaticRings', 'FractionCSP3', 'HeavyAtomCount',
        'NumHeteroatoms', 'RingCount', 'MolMR'
    ]

    # Split and train
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    if model_type == 'Random Forest':
        model = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42, n_jobs=-1)
    else:  # XGBoost
        model = xgb.XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42)
    
    model.fit(X_train, y_train)

    # Get feature importance
    importances = model.feature_importances_
    
    # Create DataFrame and sort
    importance_df = pd.DataFrame({
        'Feature': descriptor_names,
        'Importance': importances
    }).sort_values('Importance', ascending=False).head(top_n)
    
    # Plot
    plt.figure(figsize=(12, 8))
    colors = plt.cm.viridis(np.linspace(0, 1, len(importance_df)))
    bars = plt.barh(range(len(importance_df)), importance_df['Importance'], color=colors, edgecolor='black', linewidth=1.5)
    plt.yticks(range(len(importance_df)), importance_df['Feature'])
    plt.xlabel('Importance Score', fontsize=12, fontweight='bold')
    plt.ylabel('Molecular Descriptor', fontsize=12, fontweight='bold')
    plt.title(f'Top {top_n} Most Important Features\n({model_type} Model)', fontsize=14, fontweight='bold')
    plt.grid(True, alpha=0.3, axis='x')
    
    # Add value labels on bars
    for i, (bar, value) in enumerate(zip(bars, importance_df['Importance'])):
        plt.text(value, i, f' {value:.4f}', va='center', fontsize=10, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"  âœ“ Saved to: {save_path}")
    plt.close()

# =================================
# WHAT WE NEED FROM THE MAIN SCRIPT:
# =================================
def smiles_to_mol(smiles):
    try:
        return Chem.MolFromSmiles(smiles)
    except:
        return None


def generate_ecfp4_fingerprints(smiles_list):
    fingerprints = []
    for smiles in smiles_list:
        mol = smiles_to_mol(smiles)
        if mol is not None:
            fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=2048)
            arr = np.zeros((2048,))
            DataStructs.ConvertToNumpyArray(fp, arr)
            fingerprints.append(arr)
        else:
            fingerprints.append(np.zeros(2048))
    return np.array(fingerprints)


def generate_maccs_keys(smiles_list):
    maccs_list = []
    for smiles in smiles_list:
        mol = smiles_to_mol(smiles)
        if mol is not None:
            maccs = MACCSkeys.GenMACCSKeys(mol)
            arr = np.zeros((167,))
            DataStructs.ConvertToNumpyArray(maccs, arr)
            maccs_list.append(arr)
        else:
            maccs_list.append(np.zeros(167))
    return np.array(maccs_list)


def generate_rdkit_descriptors(smiles_list):
    descriptor_names = [
        'MolWt', 'MolLogP', 'NumHDonors', 'NumHAcceptors',
        'TPSA', 'NumRotatableBonds', 'NumAromaticRings',
        'NumAliphaticRings', 'FractionCSP3', 'HeavyAtomCount',
        'NumHeteroatoms', 'RingCount', 'MolMR'
    ]
    descriptor_data = []
    for smiles in smiles_list:
        mol = smiles_to_mol(smiles)
        if mol is not None:
            desc_values = []
            for desc_name in descriptor_names:
                try:
                    desc_func = getattr(Descriptors, desc_name)
                    value = desc_func(mol)
                    desc_values.append(value)
                except:
                    desc_values.append(0)
            descriptor_data.append(desc_values)
        else:
            descriptor_data.append([0] * len(descriptor_names))
    return np.array(descriptor_data)


def generate_combined_descriptors(smiles_list):
    ecfp4 = generate_ecfp4_fingerprints(smiles_list)
    maccs = generate_maccs_keys(smiles_list)
    rdkit_desc = generate_rdkit_descriptors(smiles_list)
    combined = np.hstack([ecfp4, maccs, rdkit_desc])
    return combined

# Main Visualization function
def create_all_visualizations():
    print("\n" + "=" * 80)
    print("QSAR VISUALIZATION SUITE")
    print("=" * 80)
    print("\nThis will create comprehensive visualizations for your QSAR analysis.")
    print("All plots will be saved in the 'plots/' directory.\n")
    
    # Create plots directory
    import os
    if not os.path.exists('plots'):
        os.makedirs('plots')
        print("âœ“ Created 'plots' directory\n")
    
    # Load Date
    try:
        print("Loading Data...")
        from tdc.single_pred import ADME
        data = ADME(name = 'Lipophilicity_AstraZeneca')
        df = data.get_data()
        print(f"âœ“ Loaded {len(df)} molecules\n")
    except ImportError:
        print("ERROR: TDC not installed. Install with: pip install PyTDC")
        return
    
    # Load results if available
    try:
        results_df = pd.read_csv('qsar_results.csv')
        print("âœ“ Loaded results from 'qsar_results.csv'\n")
    except FileNotFoundError:
        print("âš  WARNING: 'qsar_results.csv' not found.")
        print("  Run your main QSAR script first to generate results.\n")
        results_df = None

    print("\n" + "=" * 80)
    print("CREATING VISUALIZATIONS")
    print("=" * 80)
    
    # 1. Data distribution plots
    plot_lipophilicity_distribution(df)
    plot_molecular_property_correlations(df)
    
    # 2. Model comparison plots (if results available)
    if results_df is not None:
        plot_model_comparison_bars(results_df)
        plot_metric_heatmap(results_df)
    
    # 3. Prediction quality plots (for best model)
    model, X_test, y_test, y_test_pred = plot_predicted_vs_actual(
        df, descriptor_type='Combined', model_type='XGBoost'
    )
    plot_residuals(y_test, y_test_pred, descriptor_type='Combined', model_type='XGBoost')
    
    # 4. Feature importance plots
    plot_feature_importance_rdkit(df, model_type='Random Forest')
    plot_feature_importance_rdkit(df, model_type='XGBoost', 
                                 save_path='plots/feature_importance_rdkit_xgb.png')
    
    print("\n" + "=" * 80)
    print("VISUALIZATION COMPLETE!")
    print("=" * 80)
    print("\nAll plots have been saved to the 'plots/' directory:")
    print("  1. lipophilicity_distribution.png - Shows data distribution")
    print("  2. property_correlations.png - Feature correlation heatmap")
    if results_df is not None:
        print("  3. model_comparison.png - Bar charts comparing all models")
        print("  4. metric_heatmap.png - Heatmap of all metrics")
    print("  5. predicted_vs_actual.png - Prediction quality scatter plots")
    print("  6. residual_plot.png - Residual analysis")
    print("  7. feature_importance_rdkit.png - Important features (RF)")
    print("  8. feature_importance_rdkit_xgb.png - Important features (XGB)")
    print("\nâœ“ All visualizations created successfully!")
    print("=" * 80)

if __name__ == "__main__":
    create_all_visualizations()